{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Percentage van NaN-waarden per kolom\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m nan_percentage \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(nan_percentage[nan_percentage \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# Percentage van NaN-waarden per kolom\n",
    "nan_percentage = data.isna().mean() * 100\n",
    "print(nan_percentage[nan_percentage > 0].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.linear_model import Lasso\n",
    "# from sklearn.decomposition import PCA\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# # Zet een vaste seed\n",
    "# np.random.seed(42)\n",
    "# tf.random.set_seed(42)\n",
    "\n",
    "# # Stap 1: Schaal de data naar de range [0, 1] voor betere prestaties met LSTM\n",
    "# scaler = MinMaxScaler()\n",
    "# X_scaled = scaler.fit_transform(X)  # X moet een numpy array zijn\n",
    "\n",
    "# # Stap 2: Correlatiematrix-analyse (optioneel, voor redundante features)\n",
    "# feature_df = pd.DataFrame(X_scaled, columns=[f\"Feature_{i}\" for i in range(X_scaled.shape[1])])\n",
    "# correlation_matrix = feature_df.corr()\n",
    "# correlation_threshold = 0.9  # Stel een correlatiedrempel in\n",
    "# correlated_features = set()\n",
    "# for i in range(len(correlation_matrix.columns)):\n",
    "#     for j in range(i):\n",
    "#         if abs(correlation_matrix.iloc[i, j]) > correlation_threshold:\n",
    "#             colname = correlation_matrix.columns[i]\n",
    "#             correlated_features.add(colname)\n",
    "\n",
    "# # Verwijder sterk gecorreleerde features\n",
    "# feature_df_reduced = feature_df.drop(columns=correlated_features)\n",
    "# X_reduced = feature_df_reduced.values\n",
    "# print(f\"Sterk gecorreleerde features verwijderd: {correlated_features}\")\n",
    "\n",
    "\n",
    "\n",
    "# threshold = 0.05  # Stel een drempelwaarde in\n",
    "# X['Significant_Change'] = (X['Change'].abs() > threshold).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "# # Stap 3: PCA toepassen (optioneel, voor dimensiereductie)\n",
    "# pca = PCA(n_components=10)  # Kies het aantal gewenste componenten\n",
    "# X_pca = pca.fit_transform(X_reduced)\n",
    "# print(f\"Vorm van X_pca: {X_pca.shape}\")\n",
    "# print(f\"Verklaarde variatie door componenten: {pca.explained_variance_ratio_}\")\n",
    "\n",
    "# # Stap 4: Pas Lasso toe voor feature selectie\n",
    "# lasso = Lasso(alpha=0.0001)  # Kies een lage alpha-waarde\n",
    "# lasso.fit(X_pca, y)  # Pas Lasso aan op de PCA-componenten en de targets\n",
    "\n",
    "# # Haal de geselecteerde features op\n",
    "# selected_features = np.where(lasso.coef_ != 0)[0]  # Indices van niet-nul coëfficiënten\n",
    "# print(f\"Geselecteerde features (indexen): {selected_features}\")\n",
    "\n",
    "# # Filter X_pca om alleen de geselecteerde features te behouden\n",
    "# X_selected = X_pca[:, selected_features] if selected_features.size > 0 else X_pca\n",
    "\n",
    "# # X_selected = X_reduced\n",
    "\n",
    "# # Stap 5: Maak sequenties van tijdstappen voor het LSTM-model\n",
    "# def create_sequences(X, y, seq_length=30):\n",
    "#     X_seqs, y_seqs = [], []\n",
    "#     for i in range(len(X) - seq_length):\n",
    "#         X_seqs.append(X[i:i + seq_length])\n",
    "#         y_seqs.append(y.iloc[i + seq_length])  # Gebruik iloc voor numerieke positie\n",
    "#     return np.array(X_seqs), np.array(y_seqs)\n",
    "\n",
    "# # Gebruik 30 dagen als sequentielengte (je kunt dit aanpassen)\n",
    "# X_seqs, y_seqs = create_sequences(X_selected, y, seq_length)\n",
    "\n",
    "# # Stap 6: Train-test split (80-20)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_seqs, y_seqs, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Stap 7: Bouw het model\n",
    "# model = Sequential([\n",
    "#     Input(shape=(X_train.shape[1], X_train.shape[2])),  \n",
    "#     LSTM(50, return_sequences=True),\n",
    "#     Dropout(0.1),                                      # Dropout om overfitting te voorkomen\n",
    "#     LSTM(50, return_sequences=False),\n",
    "#     Dropout(0.1),\n",
    "#     Dense(1, activation='sigmoid')                     # Outputlaag voor classificatie (voor binair)\n",
    "# ])\n",
    "\n",
    "# def custom_loss(y_true, y_pred):\n",
    "#     change_weight = 2.0  # Geef meer gewicht aan fouten bij 'Change'\n",
    "#     return tf.reduce_mean(tf.square(y_true - y_pred) * change_weight)\n",
    "\n",
    "# # Compileer het model met een lagere learning rate\n",
    "# # model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# model.compile(optimizer=Adam(learning_rate=0.0001), loss=custom_loss, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# # Stap 4: Voeg early stopping toe\n",
    "# early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# # Train het model met meer epochs\n",
    "# history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "# from sklearn.calibration import CalibratedClassifierCV\n",
    "# import pandas as pd\n",
    "# import pandas_ta as ta\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# def fin_model_1(df, param_grid=None):\n",
    "#     \"\"\"\n",
    "#     Voegt kolommen toe voor signalen en probabiliteiten aan de originele dataset.\n",
    "\n",
    "#     Args:\n",
    "#     df (pd.DataFrame): De originele dataset.\n",
    "#     param_grid (dict): Parameter grid voor modeloptimalisatie.\n",
    "\n",
    "#     Returns:\n",
    "#     pd.DataFrame: De originele dataset met 'Signal_fin_model_1' en 'Probability_fin_model_1'.\n",
    "#     \"\"\"\n",
    "#     # Reset index en verwerk data\n",
    "#     if df.index.name == 'Date' or isinstance(df.index, pd.DatetimeIndex):\n",
    "#         df = df.reset_index()\n",
    "\n",
    "#     # Vereiste kolommen\n",
    "#     df2 = df[['Date', 'Close', 'High', 'Low', 'Open', 'Volume']].copy()\n",
    "#     df2 = df2[df2.High != df2.Low]\n",
    "#     df2.reset_index(inplace=True, drop=True)\n",
    "\n",
    "#     # Bereken technische indicatoren\n",
    "#     df2.ta.bbands(append=True, length=30, std=2)\n",
    "#     df2.ta.rsi(append=True, length=14)\n",
    "#     df2['atr'] = ta.atr(low=df2.Low, close=df2.Close, high=df2.High, length=14)\n",
    "\n",
    "#     # Hernoem kolommen\n",
    "#     df2.rename(columns={\n",
    "#         'BBL_30_2.0': 'bbl', 'BBM_30_2.0': 'bbm', 'BBU_30_2.0': 'bbh', 'RSI_14': 'rsi'\n",
    "#     }, inplace=True)\n",
    "#     df2['bb_width'] = (df2['bbh'] - df2['bbl']) / df2['bbm']\n",
    "#     df2['Signal_fin_model_1'] = 0\n",
    "\n",
    "#     # Bereken signalen\n",
    "#     for i in range(1, len(df2)):\n",
    "#         if (df2['Close'].iloc[i - 1] < df2['bbl'].iloc[i - 1] and\n",
    "#             df2['rsi'].iloc[i - 1] < 30 and\n",
    "#             df2['Close'].iloc[i] > df2['High'].iloc[i - 1] and\n",
    "#             df2['bb_width'].iloc[i] > 0.0015):\n",
    "#             df2.at[i, 'Signal_fin_model_1'] = 1\n",
    "\n",
    "#     # Bereid de data voor modeltraining\n",
    "#     df2 = df2.dropna()\n",
    "#     feature_columns = ['Close', 'High', 'Low', 'Open', 'Volume', 'bb_width', 'rsi', 'atr']\n",
    "#     X = df2[feature_columns]\n",
    "#     y = df2['Signal_fin_model_1']\n",
    "\n",
    "#     # Schalen en balanceren\n",
    "#     scaler = MinMaxScaler()\n",
    "#     X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "#     sm = SMOTE(random_state=42)\n",
    "#     X_balanced, y_balanced = sm.fit_resample(X_scaled, y)\n",
    "\n",
    "#     # Modeloptimalisatie\n",
    "#     model = LogisticRegression()\n",
    "#     if param_grid is None:\n",
    "#         param_grid = {'C': [0.1, 1, 10], 'solver': ['lbfgs'], 'max_iter': [100, 200]}\n",
    "\n",
    "#     grid_search = GridSearchCV(model, param_grid, cv=3, scoring='roc_auc')\n",
    "#     grid_search.fit(X_balanced, y_balanced)\n",
    "\n",
    "#     # Calibreer het model en bereken probabiliteiten\n",
    "#     calibrated_model = CalibratedClassifierCV(grid_search.best_estimator_, method='sigmoid', cv=3)\n",
    "#     calibrated_model.fit(X_balanced, y_balanced)\n",
    "\n",
    "#     probabilities = calibrated_model.predict_proba(X_scaled)[:, 1]\n",
    "\n",
    "#     # Voeg de berekende kolommen toe aan df2\n",
    "#     df2['Probability_fin_model_1'] = probabilities\n",
    "\n",
    "#     # Combineer de resultaten terug met de originele dataset\n",
    "#     df = df.merge(\n",
    "#         df2[['Date', 'Signal_fin_model_1', 'Probability_fin_model_1']],\n",
    "#         on='Date',\n",
    "#         how='left'\n",
    "#     )\n",
    "    \n",
    "#     df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "#     df.set_index('Date', inplace=True)\n",
    "\n",
    "\n",
    "#     return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Bereken de indicatoren en voeg ze toe aan de data\n",
    "# def add_indicators(data, lagg=30, window=20):\n",
    "#     # Voeg de 'Change' kolom toe voor de procentuele verandering\n",
    "#     data['Change'] = data['Close'].pct_change()\n",
    "\n",
    "#     # Gebruik een dictionary om nieuwe kolommen op te slaan\n",
    "#     new_columns = {}\n",
    "\n",
    "#     # Target (of de prijs stijgt morgen)\n",
    "#     new_columns['Target'] = (data['Close'].shift(-1) > data['Close']).astype(int)\n",
    "#     new_columns['Target'] = np.where(data['Change'] > 0, 1, 0)\n",
    "\n",
    "#     # data['Target'] = (data['Open'].shift(-1) > data['Close']).astype(int)\n",
    "\n",
    "\n",
    "#     # Moving Averages\n",
    "#     new_columns['MA_5'] = data['Close'].rolling(window=5).mean()\n",
    "#     new_columns['MA_10'] = data['Close'].rolling(window=10).mean()\n",
    "#     new_columns['MA_20'] = data['Close'].rolling(window=20).mean()\n",
    "\n",
    "#     # EMA en MACD\n",
    "#     ema_12 = data['Close'].ewm(span=12, adjust=False).mean()\n",
    "#     ema_26 = data['Close'].ewm(span=26, adjust=False).mean()\n",
    "#     new_columns['EMA_12'] = ema_12\n",
    "#     new_columns['EMA_26'] = ema_26\n",
    "#     new_columns['MACD'] = ema_12 - ema_26\n",
    "\n",
    "#     # Bollinger Bands\n",
    "#     bollinger_mid = data['Close'].rolling(window=20).mean()\n",
    "#     bollinger_std = data['Close'].rolling(window=20).std()\n",
    "#     new_columns['Bollinger_Mid'] = bollinger_mid\n",
    "#     new_columns['Bollinger_Upper'] = bollinger_mid + 2 * bollinger_std\n",
    "#     new_columns['Bollinger_Lower'] = bollinger_mid - 2 * bollinger_std\n",
    "\n",
    "#     # Stochastic Oscillator\n",
    "#     low_14 = data['Low'].rolling(window=14).min()\n",
    "#     high_14 = data['High'].rolling(window=14).max()\n",
    "#     new_columns['Stochastic'] = 100 * ((data['Close'] - low_14) / (high_14 - low_14))\n",
    "\n",
    "#     # Relative Strength Index (RSI)\n",
    "#     delta = data['Close'].diff()\n",
    "#     gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "#     loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "#     rs = gain / loss\n",
    "#     new_columns['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "#     # Volume Weighted Average Price (VWAP)\n",
    "#     new_columns['VWAP'] = (data['Close'] * data['Volume']).cumsum() / data['Volume'].cumsum()\n",
    "\n",
    "#     # Volatiliteit en kalender features\n",
    "#     new_columns['Volatility'] = (data['High'] - data['Low']) / data['Open']\n",
    "#     new_columns['Day_of_Week'] = pd.to_datetime(data.index).dayofweek\n",
    "#     new_columns['Month'] = pd.to_datetime(data.index).month\n",
    "#     new_columns['Quarter'] = pd.to_datetime(data.index).quarter\n",
    "\n",
    "#     # Feestdagen in de VS (zoals Thanksgiving, Kerstmis, etc.)\n",
    "#     from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "#     cal = USFederalHolidayCalendar()\n",
    "#     holidays = cal.holidays(start=data.index.min(), end=data.index.max())\n",
    "#     new_columns['Is_Holiday'] = data.index.isin(holidays).astype(int)\n",
    "\n",
    "#     # Lag-variabelen toevoegen voor een aantal dagen\n",
    "#     for lag in range(1, lagg):\n",
    "#         new_columns[f'Prev_Close_{lag}'] = data['Close'].shift(lag)\n",
    "#         new_columns[f'Prev_Change_{lag}'] = data['Change'].shift(lag)\n",
    "#         new_columns[f'Prev_Open_{lag}'] = data['Open'].shift(lag)\n",
    "\n",
    "#     # Resistance en Support niveaus\n",
    "#     new_columns['Resistance'] = data['High'].rolling(window=window).max()\n",
    "#     new_columns['Support'] = data['Low'].rolling(window=window).min()\n",
    "\n",
    "#     # Voeg alle nieuwe kolommen in één keer toe\n",
    "#     new_columns_df = pd.DataFrame(new_columns, index=data.index)\n",
    "#     data = pd.concat([data, new_columns_df], axis=1)\n",
    "\n",
    "#     # Verwijder eventuele null-waardes die door de lag-variabelen en indicatoren zijn ontstaan\n",
    "#     data.dropna(inplace=True)\n",
    "\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout, Masking\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from tensorflow.keras.metrics import Accuracy\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout, Input\n",
    "\n",
    "\n",
    "# # Stap 1: Schaal de data naar de range [0, 1] voor betere prestaties met LSTM\n",
    "# scaler = MinMaxScaler()\n",
    "# X_scaled = scaler.fit_transform(X)  # X moet een numpy array zijn\n",
    "\n",
    "# # Stap 2: Maak sequenties van tijdstappen voor het LSTM-model\n",
    "# # We maken sequenties van bijvoorbeeld 30 dagen om de volgende dag te voorspellen\n",
    "# def create_sequences(X, y, seq_length=30):\n",
    "#     X_seqs, y_seqs = [], []\n",
    "#     for i in range(len(X) - seq_length):\n",
    "#         X_seqs.append(X[i:i + seq_length])\n",
    "#         y_seqs.append(y.iloc[i + seq_length])  # Gebruik iloc voor numerieke positie\n",
    "#     return np.array(X_seqs), np.array(y_seqs)\n",
    "\n",
    "\n",
    "# # Gebruik 30 dagen als sequentielengte (je kunt dit aanpassen)\n",
    "# seq_length = 30\n",
    "# X_seqs, y_seqs = create_sequences(X_scaled, y, seq_length)\n",
    "\n",
    "# # Train-test split (80-20)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_seqs, y_seqs, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Bouw het model \n",
    "# model = Sequential([\n",
    "#     Input(shape=(X_train.shape[1], X_train.shape[2])),  \n",
    "#     LSTM(100, return_sequences=True),\n",
    "#     Dropout(0.2),                                      # Dropout om overfitting te voorkomen\n",
    "#     LSTM(50, return_sequences=False),\n",
    "#     Dropout(0.1),\n",
    "#     Dense(1, activation='sigmoid')                     # Outputlaag voor classificatie (voor binair\n",
    "# ])\n",
    "\n",
    "# # Compileer het model met een lagere learning rate\n",
    "# model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # # Stap 4: Voeg early stopping toe\n",
    "# # early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# # Train het model met meer epochs\n",
    "# history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Controleer of de 'Date'-kolom aanwezig is in het DataFrame\n",
    "# if 'Date' in df_fin_model_1.columns:\n",
    "#     # Converteer de 'Date'-kolom naar datetime (voor de zekerheid)\n",
    "#     df_fin_model_1['Date'] = pd.to_datetime(df_fin_model_1['Date'], errors='coerce')\n",
    "    \n",
    "#     # Stel de 'Date'-kolom in als index\n",
    "#     df_fin_model_1.set_index('Date', inplace=True)\n",
    "#     print(\"De 'Date'-kolom is ingesteld als index.\")\n",
    "# else:\n",
    "#     print(\"'Date'-kolom niet gevonden in df_fin_model_1.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import yfinance as yf\n",
    "\n",
    "# # Bereken de indicatoren en voeg ze toe aan de data\n",
    "# def add_indicators(data, lagg=30, window=20):\n",
    "#     # Voeg de 'Change' kolom toe voor de procentuele verandering\n",
    "#     data['Change'] = data['Close'].pct_change()\n",
    "\n",
    "#     # Bereken de verschillende indicatoren\n",
    "#     new_columns = pd.DataFrame(index=data.index)\n",
    "\n",
    "#     # Target (of de prijs stijgt morgen)\n",
    "#     new_columns['Target'] = (data['Close'].shift(-1) > data['Close']).astype(int)\n",
    "\n",
    "#     # Moving Averages\n",
    "#     new_columns['MA_5'] = data['Close'].rolling(window=5).mean()\n",
    "#     new_columns['MA_10'] = data['Close'].rolling(window=10).mean()\n",
    "#     new_columns['MA_20'] = data['Close'].rolling(window=20).mean()\n",
    "\n",
    "#     # EMA en MACD\n",
    "#     new_columns['EMA_5'] = data['Close'].ewm(span=5, adjust=False).mean()\n",
    "#     new_columns['EMA_10'] = data['Close'].ewm(span=10, adjust=False).mean()\n",
    "#     new_columns['EMA_12'] = data['Close'].ewm(span=12, adjust=False).mean()\n",
    "#     new_columns['EMA_26'] = data['Close'].ewm(span=26, adjust=False).mean()\n",
    "#     new_columns['MACD'] = new_columns['EMA_12'] - new_columns['EMA_26']\n",
    "\n",
    "#     # Bollinger Bands\n",
    "#     bollinger_mid = data['Close'].rolling(window=20).mean()\n",
    "#     bollinger_std = data['Close'].rolling(window=20).std()\n",
    "#     new_columns['Bollinger_Mid'] = bollinger_mid\n",
    "#     new_columns['Bollinger_Upper'] = bollinger_mid + 2 * bollinger_std\n",
    "#     new_columns['Bollinger_Lower'] = bollinger_mid - 2 * bollinger_std\n",
    "\n",
    "#     # Stochastic Oscillator\n",
    "#     low_14 = data['Low'].rolling(window=14).min()\n",
    "#     high_14 = data['High'].rolling(window=14).max()\n",
    "#     new_columns['Stochastic'] = 100 * ((data['Close'] - low_14) / (high_14 - low_14))\n",
    "\n",
    "#     # Relative Strength Index (RSI)\n",
    "#     delta = data['Close'].diff()\n",
    "#     gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "#     loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "#     rs = gain / loss\n",
    "#     new_columns['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "#     # Volume Weighted Average Price (VWAP)\n",
    "#     new_columns['VWAP'] = (data['Close'] * data['Volume']).cumsum() / data['Volume'].cumsum()\n",
    "\n",
    "#     # Volatiliteit en kalender features\n",
    "#     new_columns['Volatility'] = (data['High'] - data['Low']) / data['Open']\n",
    "#     new_columns['Day_of_Week'] = pd.to_datetime(data.index).dayofweek\n",
    "#     new_columns['Month'] = pd.to_datetime(data.index).month\n",
    "#     new_columns['Quarter'] = pd.to_datetime(data.index).quarter\n",
    "\n",
    "#     # Feestdagen in de VS (zoals Thanksgiving, Kerstmis, etc.)\n",
    "#     from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "#     cal = USFederalHolidayCalendar()\n",
    "#     holidays = cal.holidays(start=data.index.min(), end=data.index.max())\n",
    "#     new_columns['Is_Holiday'] = data.index.isin(holidays).astype(int)\n",
    "\n",
    "#     # Lag-variabelen toevoegen voor een aantal dagen\n",
    "#     for lag in range(1, lagg):\n",
    "#         new_columns[f'Prev_Close_{lag}'] = data['Close'].shift(lag)\n",
    "#         new_columns[f'Prev_Change_{lag}'] = data['Change'].shift(lag)\n",
    "#         new_columns[f'Prev_Open_{lag}'] = data['Open'].shift(lag)\n",
    "\n",
    "#     # Resistance en Support niveaus\n",
    "#     new_columns['Resistance'] = data['High'].rolling(window=window).max()\n",
    "#     new_columns['Support'] = data['Low'].rolling(window=window).min()\n",
    "\n",
    "#     # Voeg alle nieuwe kolommen samen met de bestaande data\n",
    "#     data = pd.concat([data, new_columns], axis=1)\n",
    "\n",
    "#     # Verwijder eventuele null-waardes die door de lag-variabelen en indicatoren zijn ontstaan\n",
    "#     data.dropna(inplace=True)\n",
    "\n",
    "#     return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# model = LogisticRegression(class_weight='balanced')\n",
    "# model.fit(X,y)\n",
    "# model.predict(X)\n",
    "# df_spy_with_sentiment['prediction_LR'] = model.predict(X)\n",
    "# df_spy_with_sentiment\n",
    "# df_spy_with_sentiment['strat'] = df_spy_with_sentiment['prediction_LR'] * df_spy_with_sentiment['Change']\n",
    "# (df_spy_with_sentiment[['strat', 'Change']] + 1).cumprod()\n",
    "# df_spy_with_sentiment['Cumulative_Strat'] = (df_spy_with_sentiment['strat'] + 1).cumprod()\n",
    "# df_spy_with_sentiment['Cumulative_Change'] = (df_spy_with_sentiment['Change'] + 1).cumprod()\n",
    "# df_spy_with_sentiment[['Cumulative_Strat', 'Cumulative_Change']].plot(title=\"Cumulatieve Rendementen\", figsize=(12, 6))\n",
    "# plt.xlabel(\"Datum\")\n",
    "# plt.ylabel(\"Cumulatief Rendement\")\n",
    "# plt.legend([\"Strategie\", \"Buy and Hold\"])\n",
    "# plt.show()\n",
    "# (df_spy_with_sentiment[['strat', 'Change']] + 1).cumprod().plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Voeg de voorspellingen toe aan het DataFrame\n",
    "# df_with_predictions = linearmodel.predict_close_with_linear_model(data_fundamentele2)\n",
    "\n",
    "# # Bekijk de eerste paar rijen van het verrijkte DataFrame\n",
    "# print(df_with_predictions.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestClassifierpip\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# # Voor deep learning modellen\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, LSTM, SimpleRNN\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# # Train-test split (80-20)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Machine learning modellen initialiseren\n",
    "# ml_models = {\n",
    "#     \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "#     \"LogisticRegression\": LogisticRegression(random_state=42, max_iter=500),\n",
    "#     \"SVC\": SVC(kernel='linear', random_state=42),\n",
    "#     \"KNeighbors\": KNeighborsClassifier(n_neighbors=5)\n",
    "# }\n",
    "\n",
    "# # Resultaten opslaan\n",
    "# results = {}\n",
    "\n",
    "# # Machine learning modellen trainen en evalueren\n",
    "# for model_name, model in ml_models.items():\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     results[model_name] = accuracy\n",
    "#     print(f\"{model_name} Accuracy: {accuracy:.2f}\")\n",
    "#     print(classification_report(y_test, y_pred))\n",
    "\n",
    "# # Deep learning modellen voorbereiden\n",
    "# # Voor LSTM en RNN moeten we de data herformatteren in 3D vorm (samples, timesteps, features)\n",
    "\n",
    "# # Voeg een dimensie toe aan de data voor LSTM en RNN (timesteps = 1)\n",
    "# X_train_dl = np.expand_dims(X_train, axis=1)\n",
    "# X_test_dl = np.expand_dims(X_test, axis=1)\n",
    "\n",
    "# # Functie om deep learning modellen te trainen en evalueren\n",
    "# def train_evaluate_dl_model(model, X_train, y_train, X_test, y_test, epochs=10, batch_size=32):\n",
    "#     model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#     model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "#     y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     return accuracy, classification_report(y_test, y_pred)\n",
    "\n",
    "# # LSTM model\n",
    "# lstm_model = Sequential([\n",
    "#     LSTM(50, input_shape=(X_train_dl.shape[1], X_train_dl.shape[2])),\n",
    "#     Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# lstm_accuracy, lstm_report = train_evaluate_dl_model(lstm_model, X_train_dl, y_train, X_test_dl, y_test)\n",
    "# results[\"LSTM\"] = lstm_accuracy\n",
    "# print(\"LSTM Accuracy:\", lstm_accuracy)\n",
    "# print(lstm_report)\n",
    "\n",
    "# # RNN model\n",
    "# rnn_model = Sequential([\n",
    "#     SimpleRNN(50, input_shape=(X_train_dl.shape[1], X_train_dl.shape[2])),\n",
    "#     Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# rnn_accuracy, rnn_report = train_evaluate_dl_model(rnn_model, X_train_dl, y_train, X_test_dl, y_test)\n",
    "# results[\"RNN\"] = rnn_accuracy\n",
    "# print(\"RNN Accuracy:\", rnn_accuracy)\n",
    "# print(rnn_report)\n",
    "\n",
    "# # Feedforward neural network (FFNN) zonder tijdreeksdimensie\n",
    "# ffnn_model = Sequential([\n",
    "#     Dense(50, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "#     Dense(25, activation='relu'),\n",
    "#     Dense(1, activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "# # Train en evalueer FFNN\n",
    "# ffnn_accuracy, ffnn_report = train_evaluate_dl_model(ffnn_model, X_train, y_train, X_test, y_test)\n",
    "# results[\"Feedforward NN\"] = ffnn_accuracy\n",
    "# print(\"Feedforward Neural Network Accuracy:\", ffnn_accuracy)\n",
    "# print(ffnn_report)\n",
    "\n",
    "# # Resultaten samenvatten\n",
    "# print(\"\\nSamenvatting van de accuracies:\")\n",
    "# for model_name, accuracy in results.items():\n",
    "#     print(f\"{model_name} Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from fredapi import Fred\n",
    "# from dotenv import load_dotenv\n",
    "# import os\n",
    "\n",
    "# # Laad de .env-variabelen\n",
    "# load_dotenv()\n",
    "\n",
    "# def fetch_and_merge_fred_data(api_key, tickers, start=start):\n",
    "#     \"\"\"\n",
    "#     Haalt tijdreeksen op via de FRED API en combineert ze in één DataFrame met een left join op datum.\n",
    "\n",
    "#     Parameters:\n",
    "#         api_key (str): De API-sleutel voor de FRED API.\n",
    "#         tickers (dict): Een dictionary met FRED-tickers en beschrijvingen.\n",
    "#         observation_start (str): Startdatum voor het ophalen van de data.\n",
    "\n",
    "#     Returns:\n",
    "#         pd.DataFrame: Een DataFrame met alle opgehaalde tijdreeksen, samengevoegd op datum.\n",
    "#     \"\"\"\n",
    "#     # Maak een Fred-object\n",
    "#     fred = Fred(api_key=api_key)\n",
    "\n",
    "#     # Data ophalen\n",
    "#     data_frames = []\n",
    "#     for ticker, description in tickers.items():\n",
    "#         try:\n",
    "#             # Haal de tijdreeks op\n",
    "#             series_data = fred.get_series(ticker, start=start)\n",
    "            \n",
    "#             # Zet de tijdreeks om in een DataFrame\n",
    "#             df = pd.DataFrame(series_data, columns=[ticker])\n",
    "#             df.index.name = \"date\"  # Stel datumindex in\n",
    "#             data_frames.append(df)\n",
    "            \n",
    "#             print(f\"Succesvol opgehaald: {description} ({ticker})\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Kon {description} ({ticker}) niet ophalen: {e}\")\n",
    "\n",
    "#     # Combineer alle DataFrames met een left join\n",
    "#     if data_frames:\n",
    "#         merged_data = pd.concat(data_frames, axis=1, join=\"outer\")\n",
    "#         return merged_data\n",
    "#     else:\n",
    "#         print(\"Geen data opgehaald.\")\n",
    "#         return pd.DataFrame()\n",
    "\n",
    "# # Voorbeeldgebruik\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Haal de API-sleutel op\n",
    "#     api_key = os.getenv(\"FRED_API_KEY\")\n",
    "\n",
    "\n",
    "\n",
    "#     # Roep de functie aan\n",
    "#     merged_data = fetch_and_merge_fred_data(api_key, tickers, start=start)\n",
    "\n",
    "#     # Toon de eerste paar rijen\n",
    "#     print(merged_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fredapi import Fred\n",
    "# from dotenv import load_dotenv\n",
    "# import os\n",
    "\n",
    "# # Laad de .env-variabelen\n",
    "# load_dotenv()\n",
    "\n",
    "# # Haal de API-sleutel op uit de omgeving\n",
    "# api_key = os.getenv(\"FRED_API_KEY\")\n",
    "\n",
    "# # Maak een Fred-object\n",
    "# fred = Fred(api_key=api_key)\n",
    "\n",
    "# # Lijst van relevante tickers\n",
    "# tickers = {\n",
    "#     \"UNRATE\": \"Unemployment Rate\",\n",
    "#     \"CPIAUCSL\": \"Consumer Price Index (All Urban Consumers)\",\n",
    "#     \"GDP\": \"Gross Domestic Product\",\n",
    "#     \"DGS10\": \"10-Year Treasury Constant Maturity Rate\",\n",
    "#     \"FEDFUNDS\": \"Effective Federal Funds Rate\",\n",
    "#     \"PCE\": \"Personal Consumption Expenditures\",\n",
    "#     \"INDPRO\": \"Industrial Production Index\",\n",
    "#     \"M2SL\": \"Money Stock (M2)\"\n",
    "# }\n",
    "\n",
    "# # Data ophalen met een loop\n",
    "# data = {}\n",
    "\n",
    "# for ticker, description in tickers.items():\n",
    "#     try:\n",
    "#         # Haal de tijdreeks op en voeg toe aan de dictionary\n",
    "#         series_data = fred.get_series(ticker, observation_start=start)\n",
    "#         data[ticker] = series_data\n",
    "#         print(f\"Succesvol opgehaald: {description} ({ticker})\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"Kon {description} ({ticker}) niet ophalen: {e}\")\n",
    "\n",
    "# # Optioneel: Toon data van één ticker als voorbeeld\n",
    "# print(data[\"UNRATE\"].head())  # Toon de eerste paar rijen van de werkloosheidsdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yfinance as yf\n",
    "# import pandas as pd\n",
    "\n",
    "# # Toevoegen van economische indicatoren via FRED, je zou de `fredapi` of `yfinance` gebruiken voor sommige van deze\n",
    "# tickers = {\n",
    "#     \"^VIX\": \"VIX\",    # Volatiliteitsindex\n",
    "#     \"XLK\": \"Technology\",\n",
    "#     \"XLE\": \"Energy\",\n",
    "#     \"XLF\": \"Financials\",\n",
    "#     \"XLV\": \"Healthcare\",\n",
    "#     \"^TNX\": \"10Yr_Treasury_Rate\",  # 10-jaars rente\n",
    "#     \"CPIAUSL\": \"CPI\",  # Inflatie CPI\n",
    "#     \"UNRATE\": \"Unemployment\",  # Werkloosheidscijfers\n",
    "#     \"GDP\": \"GDP Growth\",  # Bruto binnenlands product\n",
    "#     \"DJI\": \"DowJones\",  # Dow Jones\n",
    "# }\n",
    "\n",
    "# # Loop door de tickers om data op te halen en toe te voegen aan de dataset\n",
    "# for ticker, column_name in tickers.items():\n",
    "#     # Haal de data op voor de huidige ticker\n",
    "#     ticker_data = yf.download(ticker, start=\"2010-01-01\", progress=False)\n",
    "    \n",
    "#     # Controleer of er een MultiIndex is en maak deze plat\n",
    "#     if isinstance(ticker_data.columns, pd.MultiIndex):\n",
    "#         ticker_data.columns = ticker_data.columns.get_level_values(0)\n",
    "    \n",
    "#     # Gebruik alleen de slotkoers en hernoem de kolom\n",
    "#     ticker_data = ticker_data[['Close']].rename(columns={'Close': column_name})\n",
    "    \n",
    "#     # Formatteer de index naar 'YYYY-MM-DD'\n",
    "#     ticker_data.index = ticker_data.index.strftime('%Y-%m-%d')\n",
    "    \n",
    "#     # Voeg de nieuwe kolom toe aan de dataset\n",
    "#     data = data.join(ticker_data, how='left')\n",
    "    \n",
    "#     # Vul eventuele NaN-waarden in de kolom in\n",
    "#     data[column_name] = data[column_name].ffill()  # Forward fill missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Loop met YF info VIX + sectoren waaruit SMP500 bestaat (Technology, Energy, Financials, Healthcare) \n",
    "tickers = {\n",
    "    \"^VIX\": \"VIX\",\n",
    "    \"XLK\": \"XLK\",\n",
    "    \"XLE\": \"XLE\",\n",
    "    \"XLF\": \"XLF\",\n",
    "    \"XLV\": \"XLV\",\n",
    "    \"^TNX\": \"^TNX\"\n",
    "}\n",
    "\n",
    "# Loop door de tickers om data op te halen en toe te voegen aan de dataset\n",
    "for ticker, column_name in tickers.items():\n",
    "    # Haal de data op voor de huidige ticker\n",
    "    ticker_data = yf.download(ticker, start=\"2010-01-01\", progress=False)\n",
    "    \n",
    "    # Controleer of er een MultiIndex is en maak deze plat\n",
    "    if isinstance(ticker_data.columns, pd.MultiIndex):\n",
    "        ticker_data.columns = ticker_data.columns.get_level_values(0)\n",
    "    \n",
    "    # Gebruik alleen de slotkoers en hernoem de kolom\n",
    "    ticker_data = ticker_data[['Close']].rename(columns={'Close': column_name})\n",
    "    \n",
    "    # Formatteer de index naar 'YYYY-MM-DD'\n",
    "    ticker_data.index = ticker_data.index.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Voeg de nieuwe kolom toe aan de dataset\n",
    "    data = data.join(ticker_data, how='left')\n",
    "    \n",
    "    # Vul eventuele NaN-waarden in de kolom in\n",
    "    data[column_name] = data[column_name].ffill()  # Forward fill missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Selecteer de features en het target\n",
    "# lag_features = [f'Prev_Close_{i}' for i in range(1, lagg)] + \\\n",
    "#                [f'Prev_Change_{i}' for i in range(1, lagg)] + \\\n",
    "#                [f'Prev_Open_{i}' for i in range(1, lagg)]\n",
    "# extra_features = ['Change', 'MA_5', 'MA_10', 'MA_20', 'EMA_5', 'EMA_10', 'EMA_12', 'EMA_26', 'RSI', \n",
    "#                   'Volatility', 'Day_of_Week', 'Month', '^TNX', 'MACD', 'Bollinger_Upper', 'Bollinger_Lower', 'Stochastic', 'VWAP', 'Quarter','Is_Holiday','XLK', 'XLE', 'XLF', 'XLV', 'compound', 'Resistance', 'Support']\n",
    "\n",
    "# X = df_spy_with_sentiment[lag_features + extra_features]\n",
    "# y = df_spy_with_sentiment['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# De Amerikaanse 10-jaars rente op als extra feature\n",
    "treasury_data = yf.download(\"^TNX\", start=\"2010-01-01\", progress=False)  # 'end' parameter weggelaten\n",
    "\n",
    "# Controleer ook of treasury_data een MultiIndex heeft en maak deze plat\n",
    "if isinstance(treasury_data.columns, pd.MultiIndex):\n",
    "    treasury_data.columns = treasury_data.columns.get_level_values(0)\n",
    "\n",
    "# Gebruik alleen de slotkoers en hernoem de kolom\n",
    "treasury_data = treasury_data[['Close']].rename(columns={'Close': 'Treasury_Rate'})\n",
    "\n",
    "# Vul eventuele missende data voorwaarts in treasury_data om de dagelijkse frequentie consistent te maken\n",
    "treasury_data = treasury_data.ffill()\n",
    "\n",
    "# Voeg de 10-jaars rente data samen met de S&P 500 data\n",
    "# data = data.join(treasury_data, how='inner')  \n",
    "# Voeg de 10-jaars rente data samen met de S&P 500 data, met een suffix voor overlappende kolommen\n",
    "data = data.join(treasury_data, how='inner', rsuffix='_Treasury')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target\n",
    "data['Target'] = (data['Close'].shift(-1) > data['Close']).astype(int)\n",
    "\n",
    "# Moving Averages\n",
    "data['MA_5'] = data['Close'].rolling(window=5).mean()\n",
    "data['MA_10'] = data['Close'].rolling(window=10).mean()\n",
    "data['MA_20'] = data['Close'].rolling(window=20).mean()\n",
    "\n",
    "# EMA en MACD (Moving Average Convergence Divergence)(12- en 26-daags exponentieel voortschrijdend gemiddelde)\n",
    "data['EMA_5'] = data['Close'].ewm(span=5, adjust=False).mean()\n",
    "data['EMA_10'] = data['Close'].ewm(span=10, adjust=False).mean()\n",
    "data['EMA_12'] = data['Close'].ewm(span=12, adjust=False).mean()\n",
    "data['EMA_26'] = data['Close'].ewm(span=26, adjust=False).mean()\n",
    "data['MACD'] = data['EMA_12'] - data['EMA_26']\n",
    "\n",
    "# Bollinger Bands (20-daags voortschrijdend gemiddelde en 2 standaarddeviaties)\n",
    "data['Bollinger_Mid'] = data['Close'].rolling(window=20).mean()\n",
    "data['Bollinger_Upper'] = data['Bollinger_Mid'] + 2 * data['Close'].rolling(window=20).std()\n",
    "data['Bollinger_Lower'] = data['Bollinger_Mid'] - 2 * data['Close'].rolling(window=20).std()\n",
    "\n",
    "# Stochastic Oscillator\n",
    "low_14 = data['Low'].rolling(window=14).min()\n",
    "high_14 = data['High'].rolling(window=14).max()\n",
    "data['Stochastic'] = 100 * ((data['Close'] - low_14) / (high_14 - low_14))\n",
    "\n",
    "# Relative Strength Index (RSI)\n",
    "delta = data['Close'].diff()\n",
    "gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "rs = gain / loss\n",
    "data['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "# Percentage Change\n",
    "data['Change'] = data['Close'].pct_change()\n",
    "\n",
    "# Volume Weighted Average Price\n",
    "data['VWAP'] = (data['Close'] * data['Volume']).cumsum() / data['Volume'].cumsum()\n",
    "\n",
    "# Volatiliteit en kalender features toevoegen\n",
    "data['Volatility'] = (data['High'] - data['Low']) / data['Open']\n",
    "data['Day_of_Week'] = pd.to_datetime(data.index).dayofweek\n",
    "data['Month'] = pd.to_datetime(data.index).month\n",
    "data['Quarter'] = pd.to_datetime(data.index).quarter\n",
    "\n",
    "# Feestdagen in de VS (zoals Thanksgiving, Kerstmis, etc.)\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "\n",
    "cal = USFederalHolidayCalendar()\n",
    "holidays = cal.holidays(start=data.index.min(), end=data.index.max())\n",
    "data['Is_Holiday'] = data.index.isin(holidays).astype(int)\n",
    "\n",
    "# Lag-variabelen toevoegen voor een aantal dagen\n",
    "lagg = 30\n",
    "for lag in range(1, lagg):\n",
    "    data[f'Prev_Close_{lag}'] = data['Close'].shift(lag)\n",
    "    data[f'Prev_Change_{lag}'] = data['Change'].shift(lag)\n",
    "    data[f'Prev_Open_{lag}'] = data['Open'].shift(lag)\n",
    "\n",
    "window = 20\n",
    "# Resistance is het hoogste punt binnen het venster\n",
    "data['Resistance'] = data['High'].rolling(window=window).max()\n",
    "\n",
    "# Support is het laagste punt binnen het venster\n",
    "data['Support'] = data['Low'].rolling(window=window).min()\n",
    "\n",
    "# Verwijder eventuele null-waardes die door de lag-variabelen en indicatoren zijn ontstaan\n",
    "data.dropna(inplace=True)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analyse  \n",
    "\n",
    "from urllib.request import urlopen, Request\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "finviz_url = 'https://finviz.com/quote.ashx?t=SPY&p=d'\n",
    "tickers = ['SPY']\n",
    "\n",
    "news_tables = {}\n",
    "for ticker in tickers:\n",
    "    url = finviz_url + ticker\n",
    "\n",
    "    req = Request(url=url, headers={'user-agent': 'my-app'})\n",
    "    response = urlopen(req)\n",
    "\n",
    "    html = BeautifulSoup(response, features='html.parser')\n",
    "    news_table = html.find(id='news-table')\n",
    "    news_tables[ticker] = news_table\n",
    "\n",
    "    import pandas as pd\n",
    "\n",
    "parsed_data = []\n",
    "previous_date = None  # Houd de vorige datum bij\n",
    "\n",
    "for ticker, news_table in news_tables.items():\n",
    "    for row in news_table.findAll('tr'):\n",
    "\n",
    "        title = row.a.text  # Haal de titel van het nieuwsartikel\n",
    "        timestamp = row.td.text.strip()  # Haal de timestamp uit de td en strip eventuele spaties\n",
    "\n",
    "        # Split de timestamp in datum en tijd\n",
    "        date_data = timestamp.split(' ')\n",
    "\n",
    "        # Controleer of we een datum hebben\n",
    "        if len(date_data) == 1:  # Geen datum, alleen tijd\n",
    "            if previous_date is not None:  # Vul de vorige datum in\n",
    "                date = previous_date\n",
    "                time = date_data[0]  # De tijd\n",
    "            else:\n",
    "                date = 'Unknown'  # Als er geen datum of vorige datum is\n",
    "                time = date_data[0]  # De tijd\n",
    "        else:  # Als we een datum en tijd hebben\n",
    "            date = date_data[0]  # De datum\n",
    "            time = date_data[1]  # De tijd\n",
    "            previous_date = date  # Sla de huidige datum op voor het volgende artikel\n",
    "\n",
    "        # Voeg de gegevens toe aan de lijst\n",
    "        parsed_data.append([ticker, date, time, title])\n",
    "\n",
    "# Zet de parsed data om in een DataFrame\n",
    "df = pd.DataFrame(parsed_data, columns=['ticker', 'date', 'time', 'title'])\n",
    "\n",
    "# Toon het resultaat\n",
    "print(df)\n",
    "\n",
    "# Sentiment analyzer initialiseren\n",
    "vader = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Functie om de sentimenten te berekenen\n",
    "f = lambda title: vader.polarity_scores(title)['compound']\n",
    "df['compound'] = df['title'].apply(f)\n",
    "\n",
    "# Datumverwerking\n",
    "def parse_date(date):\n",
    "    if date.lower() == 'today':\n",
    "        return pd.to_datetime('today').date()  # Zet 'Today' om naar de huidige datum\n",
    "    try:\n",
    "        return pd.to_datetime(date).date()  # Converteer normale datums\n",
    "    except Exception as e:\n",
    "        return None  # Als het niet lukt, return None\n",
    "\n",
    "df['date'] = df['date'].apply(parse_date)  # Pas de datumverwerking toe\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "\n",
    "# Haal de VIX-data op\n",
    "vix_data = yf.download(\"^VIX\", start=\"2010-01-01\", progress=False)\n",
    "\n",
    "# Controleer of er een MultiIndex is en maak deze plat\n",
    "if isinstance(vix_data.columns, pd.MultiIndex):\n",
    "    vix_data.columns = vix_data.columns.get_level_values(0)\n",
    "\n",
    "# Gebruik alleen de slotkoers en hernoem de kolom\n",
    "vix_data = vix_data[['Close']].rename(columns={'Close': 'VIX'})\n",
    "\n",
    "vix_data.index = vix_data.index.strftime('%Y-%m-%d')\n",
    "\n",
    "# Voeg de VIX-kolom toe aan de dataset\n",
    "data = data.join(vix_data, how='left')\n",
    "data['VIX'] = data['VIX'].ffill()  # Vul eventuele NaN-waarden in de VIX-kolom\n",
    "\n",
    "\n",
    "####\n",
    "\n",
    "# Haal de XLK-data op\n",
    "xlk_data = yf.download(\"XLK\", start=\"2010-01-01\", progress=False)\n",
    "\n",
    "# Controleer of er een MultiIndex is en maak deze plat\n",
    "if isinstance(xlk_data.columns, pd.MultiIndex):\n",
    "    xlk_data.columns = xlk_data.columns.get_level_values(0)\n",
    "\n",
    "# Gebruik alleen de slotkoers en hernoem de kolom\n",
    "xlk_data = xlk_data[['Close']].rename(columns={'Close': 'XLK'})\n",
    "\n",
    "xlk_data.index = xlk_data.index.strftime('%Y-%m-%d')\n",
    "\n",
    "# Voeg de XLK-kolom toe aan de dataset\n",
    "data = data.join(xlk_data, how='left')\n",
    "data['XLK'] = data['XLK'].ffill()  # Vul eventuele NaN-waarden in de VIX-kolom\n",
    "\n",
    "###\n",
    "\n",
    "####\n",
    "\n",
    "# Haal de XLE-data op\n",
    "xle_data = yf.download(\"XLE\", start=\"2010-01-01\", progress=False)\n",
    "\n",
    "# Controleer of er een MultiIndex is en maak deze plat\n",
    "if isinstance(xle_data.columns, pd.MultiIndex):\n",
    "    xle_data.columns = xle_data.columns.get_level_values(0)\n",
    "\n",
    "# Gebruik alleen de slotkoers en hernoem de kolom\n",
    "xle_data = xle_data[['Close']].rename(columns={'Close': 'XLE'})\n",
    "\n",
    "xle_data.index = xle_data.index.strftime('%Y-%m-%d')\n",
    "\n",
    "# Voeg de XLE-kolom toe aan de dataset\n",
    "data = data.join(xle_data, how='left')\n",
    "data['XLE'] = data['XLE'].ffill()  # Vul eventuele NaN-waarden in de VIX-kolom\n",
    "\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verwijder uren uit de datums en formatteer als YYYY-MM-DD\n",
    "data.index = data.index.strftime('%Y-%m-%d')\n",
    "\n",
    "# Stap 1: Verwijder het prefix en hernoem kolommen\n",
    "data.columns = data.columns.get_level_values(1)  # Haal de tweede niveau kolomnaam op, dus zonder '^GSPC' prefix\n",
    "\n",
    "# Hernoem kolommen om eventuele lege strings te vervangen\n",
    "data.columns = [\"Adj_Close\", \"Close\", \"High\", \"Low\", \"Open\", \"Volume\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF model is minder geschikt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Train-test split (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model initialiseren en trainen\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Voorspellingen doen\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# resultaten\n",
    "\n",
    "# Resultaten beoordelen\n",
    "\n",
    "\n",
    "# Voeg de voorspellingen toe aan de testset voor het plotten\n",
    "X_test = X_test.copy()  # Zorg ervoor dat we de testset niet overschrijven\n",
    "X_test['True_Direction'] = y_test.values\n",
    "X_test['Predicted_Direction'] = y_pred\n",
    "\n",
    "# Gebruik 'Prev_Close_1' en 'Prev_Change_1' om de werkelijke en voorspelde slotkoers te berekenen\n",
    "X_test['Actual_Close'] = X_test['Prev_Close_1'] * (1 + X_test['Prev_Change_1'])\n",
    "X_test['Predicted_Close'] = np.where(X_test['Predicted_Direction'] == 1,\n",
    "                                     X_test['Prev_Close_1'] * 1.002,\n",
    "                                     X_test['Prev_Close_1'] * 0.998)\n",
    "\n",
    "# Controleer of de voorspelde richting gelijk is aan de werkelijke richting\n",
    "X_test['Correct_Prediction'] = (X_test['True_Direction'] == X_test['Predicted_Direction'])\n",
    "\n",
    "# Tel het aantal correcte voorspellingen en de totale voorspellingen\n",
    "correct_predictions = X_test['Correct_Prediction'].sum()\n",
    "total_predictions = X_test['Correct_Prediction'].count()\n",
    "\n",
    "# Bereken het percentage correcte voorspellingen\n",
    "accuracy_direction = correct_predictions / total_predictions * 100\n",
    "\n",
    "print(f\"Aantal correcte voorspellingen: {correct_predictions} van {total_predictions}\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"Percentage correcte richtingsvoorspellingen: {accuracy_direction:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rente verbeterde het model niet\n",
    "\n",
    "# Stap 1a: Haal de Amerikaanse 10-jaars rente op als extra feature\n",
    "treasury_data = yf.download(\"^TNX\", start=\"2010-01-01\", end=\"2023-11-07\")\n",
    "\n",
    "# Zorg dat de 10-jaars rente data dezelfde frequentie heeft als de S&P 500 data door resampling\n",
    "# Resample naar dagelijkse data door voorwaarts te vullen\n",
    "treasury_data = treasury_data[['Close']].rename(columns={'Close': 'Treasury_Rate'}).ffill()\n",
    "\n",
    "# Voeg de 10-jaars rente data samen met de S&P 500 data\n",
    "data = data.join(treasury_data, how='inner')  # Samenvoegen op de datumindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalen verhoogd de accuracy niet\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# 3. Pas de scaler toe op de trainingsdata en gebruik dezelfde scaler voor de testdata\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit de scaler op de trainingsdata\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transformeer de testdata met dezelfde scaler (pas alleen transform toe, niet fit_transform)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
